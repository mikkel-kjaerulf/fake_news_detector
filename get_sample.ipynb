{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subset of full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import pyarrow.feather as feather\n",
    "import regex as re\n",
    "from cleantext import clean\n",
    "import pyarrow.feather as feather\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to load a subset of the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indhenter et sample på ca. 1,45M artikler, meget tidseffektivt\n",
    "def getSample(csvstring: str, sample_size: int):\n",
    "    random.seed(0)\n",
    "    n = 11000000 #number of records in file (excludes header)\n",
    "    s = sample_size #desired sample size\n",
    "    skip = sorted(random.sample(range(1,n+1),n-s))\n",
    "    # Read the CSV file, skipping the randomly selected rows\n",
    "    sampled_data = pd.read_csv(csvstring, on_bad_lines='skip', skiprows=skip, index_col=0)\n",
    "    sampled_data = sampled_data.reset_index()\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getSample(\"data/news_cleaned_2018_02_13-1.csv\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3905"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting The Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_freq(dataframe):\n",
    "    typedict = {}\n",
    "    for i in dataframe['type']: \n",
    "        if str(i) in typedict:\n",
    "            typedict[str(i)] +=1 \n",
    "        else: \n",
    "            typedict[str(i)] =1 \n",
    "    typedict\n",
    "    typedictperc = typedict.copy()\n",
    "    #laver et nyt dictionairy som viser det i procenttal\n",
    "    for i in typedictperc:\n",
    "        typedictperc[i] = (typedictperc[i]/(len(data)))*100\n",
    "    return typedictperc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 10.345710627400768,\n",
       " 'conspiracy': 9.807938540332907,\n",
       " 'political': 18.56594110115237,\n",
       " 'bias': 13.4955185659411,\n",
       " 'clickbait': 2.9193341869398206,\n",
       " 'nan': 5.172855313700384,\n",
       " 'unreliable': 3.6619718309859155,\n",
       " 'rumor': 5.761843790012804,\n",
       " 'junksci': 1.3060179257362354,\n",
       " 'unknown': 4.12291933418694,\n",
       " 'reliable': 22.458386683738794,\n",
       " 'hate': 1.1011523687580027,\n",
       " 'satire': 1.2804097311139564}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_type_freq(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reliable': 22.561888537768805,\n",
       " 'political': 28.617108052577617,\n",
       " 'bias': 15.280389897611691,\n",
       " 'Satire': 1.716459421738357,\n",
       " 'fake': 10.905098641191126,\n",
       " 'conspiracy': 10.645397202669349,\n",
       " 'unreliable': 3.7580450222794273,\n",
       " 'clickbait': 3.4334005989277774,\n",
       " 'junksci': 1.703052520039264,\n",
       " 'hate': 1.3791601051965903}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allArticlesCount = 928083 + 146080 + 1300444 + 905981 + 144939 + 117374 + 292201 + 2435471 + 319830 + 1920139\n",
    "#Jeg henter data from README.md om hvor mange artikler af hver type, der er i det fulde datasæt\n",
    "realtypeperc = {\"reliable\": (1920139/allArticlesCount)*100, \"political\": (2435471/allArticlesCount)*100, \"bias\": (1300444/allArticlesCount)*100, \"Satire\": (146080/allArticlesCount)*100, \"fake\": (928083/allArticlesCount)*100, \"conspiracy\":(905981/allArticlesCount)*100, \"unreliable\": (319830/allArticlesCount)*100, \"clickbait\":(292201/allArticlesCount)*100, \"junksci\":(144939/allArticlesCount)*100 , \"hate\":(117374/allArticlesCount)*100}\n",
    "realtypeperc\n",
    "#jeg præsenterer det som procenter\n",
    "#ved sammenligning er det tydeligt, at Mikkels forkortede datasæt ikke har markant anderledes proportion ift. artikeltyper, end det fulde datasæt\n",
    "#Største forskel er at der er tilføjet nye typer af artikler som rumor til datasættet, siden README blev skrevet. \n",
    "#Vi kan bruge dette til at forsikre os selv om at vores forkortede datasæt er repræsentativt for det fulde datasæt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Sample For Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we preprocess there are some articles we can remove from the data set. We also change the labels so that\n",
    "they are either 'reliable' or 'fake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klassificerer alt som reliable/fake\n",
    "def binary_labels(df): \n",
    "    #klassificerer alle de artikler vi vil bruge ind i reliable eller fake\n",
    "    df.type = df.type.replace({'political': 'reliable', 'junksci': 'fake', 'bias' : 'fake', 'satire': 'fake', 'conspiracy': 'fake', 'rumor': 'fake', 'unreliable' : 'fake', 'clickbait': 'fake', 'hate': 'fake'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = binary_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fjerner alle de artikler vi ikke skal bruges. NB: SKAL kaldes på en dataframe, som allerede har været igennem binary_labels\n",
    "def remove_bad_articles(df): \n",
    "    #fjerner artikler som har volapyk types (inklusiv 'unknown')\n",
    "    df = df[(df.type == 'reliable') |(df.type == 'fake')]\n",
    "    #fjerner artikler som ikke har nogen type\n",
    "    df = df[df.type.notnull()]\n",
    "    #fjerner artikler uden content\n",
    "    df = df[df.content.notnull()]\n",
    "    #fjerner duplerede artikler, ud over en enkelt\n",
    "    df = df.drop_duplicates(subset = 'content', keep = 'last')\n",
    "    #fjerner de artikler som ikke indeholder mindst et latinsk bogstav\n",
    "    df = df[df.content.str.contains('[a-z]')]\n",
    "    #reset index gør, at hvis vi fjerner artikle [2], bliver artikel [3] rykket ned på index [2] osv. dernedad.\n",
    "    df = df.reset_index()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_bad_articles(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3087"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelperc(df): \n",
    "    labeldict = {}\n",
    "    for i in df.type: \n",
    "        if i in labeldict: \n",
    "            labeldict[i] +=1\n",
    "        else: \n",
    "            labeldict[i] = 1\n",
    "    for i in labeldict: \n",
    "        labeldict[i] = labeldict[i]/len(df)*100\n",
    "    return labeldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 52.60770975056689, 'reliable': 47.3922902494331}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelperc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/large_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the larger sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we preprocess the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import preprocessing_functions\n",
    "import cleaning_functions\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning took 10.829108953475952 seconds\n",
      "Tokenizing took 2.480616807937622 seconds\n",
      "Removing stopwords took 0.00882101058959961 seconds\n",
      "Stemming took 0.0008168220520019531 seconds\n",
      "Converting to list took 8.656620025634766 seconds\n",
      "writing to csv took 0.15309691429138184 seconds\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/sample_preprocessed_ver_\" + datetime.today().strftime('%Y-%m-%d-%s') + \".csv\"\n",
    "for chunck in pd.read_csv(\"data/sample_structured.csv\", chunksize=10000, index_col=0):\n",
    "    cleaning_functions.clean_dataframe(chunck)\n",
    "    preprocessing_functions.preprocess(chunck)\n",
    "    start = time.time()\n",
    "    chunck.to_csv(file_name, mode='a')\n",
    "    end = time.time()\n",
    "    print(\"writing to csv took \" + str(end - start) + \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
