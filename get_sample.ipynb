{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get subset of full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "import pyarrow.feather as feather\n",
    "import regex as re\n",
    "from cleantext import clean\n",
    "import pyarrow.feather as feather\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to load a subset of the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indhenter et sample på ca. 1,45M artikler, meget tidseffektivt\n",
    "def getSample(csvstring: str, sample_size: int):\n",
    "    random.seed(0)\n",
    "    n = 11000000 #number of records in file (excludes header)\n",
    "    s = sample_size #desired sample size\n",
    "    skip = sorted(random.sample(range(1,n+1),n-s))\n",
    "    # Read the CSV file, skipping the randomly selected rows\n",
    "    sampled_data = pd.read_csv(csvstring, on_bad_lines='skip', skiprows=skip, index_col=0)\n",
    "    sampled_data = sampled_data.reset_index()\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/r8x5s5mn7jg12hs3c28wpg4c0000gn/T/ipykernel_46728/4167401217.py:8: DtypeWarning: Columns (1,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sampled_data = pd.read_csv(csvstring, on_bad_lines='skip', skiprows=skip, index_col=0)\n"
     ]
    }
   ],
   "source": [
    "data = getSample(\"data/news_cleaned_2018_02_13-1.csv\", 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77430"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting The Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_freq(dataframe):\n",
    "    typedict = {}\n",
    "    for i in dataframe['type']: \n",
    "        if str(i) in typedict:\n",
    "            typedict[str(i)] +=1 \n",
    "        else: \n",
    "            typedict[str(i)] =1 \n",
    "    typedict\n",
    "    typedictperc = typedict.copy()\n",
    "    #laver et nyt dictionairy som viser det i procenttal\n",
    "    for i in typedictperc:\n",
    "        typedictperc[i] = (typedictperc[i]/(len(data)))*100\n",
    "    return typedictperc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unreliable': 3.4844375565026473,\n",
       " 'satire': 1.312152912307891,\n",
       " 'hate': 0.9414955443626501,\n",
       " 'conspiracy': 9.816608549657756,\n",
       " 'political': 19.45886607258169,\n",
       " 'junksci': 1.3780188557406692,\n",
       " 'fake': 10.515304145679968,\n",
       " 'bias': 13.462482242025056,\n",
       " 'reliable': 22.384088854449182,\n",
       " 'clickbait': 2.6940462353093118,\n",
       " 'rumor': 5.453958414051401,\n",
       " 'nan': 4.68035645098799,\n",
       " 'unknown': 4.416892677256877,\n",
       " '2018-02-10 13:43:39.521661': 0.0012914890869172157}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_type_freq(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reliable': 22.561888537768805,\n",
       " 'political': 28.617108052577617,\n",
       " 'bias': 15.280389897611691,\n",
       " 'Satire': 1.716459421738357,\n",
       " 'fake': 10.905098641191126,\n",
       " 'conspiracy': 10.645397202669349,\n",
       " 'unreliable': 3.7580450222794273,\n",
       " 'clickbait': 3.4334005989277774,\n",
       " 'junksci': 1.703052520039264,\n",
       " 'hate': 1.3791601051965903}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allArticlesCount = 928083 + 146080 + 1300444 + 905981 + 144939 + 117374 + 292201 + 2435471 + 319830 + 1920139\n",
    "#Jeg henter data from README.md om hvor mange artikler af hver type, der er i det fulde datasæt\n",
    "realtypeperc = {\"reliable\": (1920139/allArticlesCount)*100, \"political\": (2435471/allArticlesCount)*100, \"bias\": (1300444/allArticlesCount)*100, \"Satire\": (146080/allArticlesCount)*100, \"fake\": (928083/allArticlesCount)*100, \"conspiracy\":(905981/allArticlesCount)*100, \"unreliable\": (319830/allArticlesCount)*100, \"clickbait\":(292201/allArticlesCount)*100, \"junksci\":(144939/allArticlesCount)*100 , \"hate\":(117374/allArticlesCount)*100}\n",
    "realtypeperc\n",
    "#jeg præsenterer det som procenter\n",
    "#ved sammenligning er det tydeligt, at Mikkels forkortede datasæt ikke har markant anderledes proportion ift. artikeltyper, end det fulde datasæt\n",
    "#Største forskel er at der er tilføjet nye typer af artikler som rumor til datasættet, siden README blev skrevet. \n",
    "#Vi kan bruge dette til at forsikre os selv om at vores forkortede datasæt er repræsentativt for det fulde datasæt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Sample For Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we preprocess there are some articles we can remove from the data set. We also change the labels so that\n",
    "they are either 'reliable' or 'fake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Klassificerer alt som reliable/fake\n",
    "def binary_labels(df): \n",
    "    #klassificerer alle de artikler vi vil bruge ind i reliable eller fake\n",
    "    df.type = df.type.replace({'political': 'reliable', 'junksci': 'fake', 'bias' : 'fake', 'satire': 'fake', 'conspiracy': 'fake', 'rumor': 'fake', 'unreliable' : 'fake', 'clickbait': 'fake', 'hate': 'fake'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = binary_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fjerner alle de artikler vi ikke skal bruges. NB: SKAL kaldes på en dataframe, som allerede har været igennem binary_labels\n",
    "def remove_bad_articles(df): \n",
    "    #fjerner artikler som har volapyk types (inklusiv 'unknown')\n",
    "    df = df[(df.type == 'reliable') |(df.type == 'fake')]\n",
    "    #fjerner artikler som ikke har nogen type\n",
    "    df = df[df.type.notnull()]\n",
    "    #fjerner artikler uden content\n",
    "    df = df[df.content.notnull()]\n",
    "    #fjerner duplerede artikler, ud over en enkelt\n",
    "    df = df.drop_duplicates(subset = 'content', keep = 'last')\n",
    "    #fjerner de artikler som ikke indeholder mindst et latinsk bogstav\n",
    "    df = df[df.content.str.contains('[a-z]')]\n",
    "    #reset index gør, at hvis vi fjerner artikle [2], bliver artikel [3] rykket ned på index [2] osv. dernedad.\n",
    "    df = df.reset_index()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_bad_articles(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59165"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelperc(df): \n",
    "    labeldict = {}\n",
    "    for i in df.type: \n",
    "        if i in labeldict: \n",
    "            labeldict[i] +=1\n",
    "        else: \n",
    "            labeldict[i] = 1\n",
    "    for i in labeldict: \n",
    "        labeldict[i] = labeldict[i]/len(df)*100\n",
    "    return labeldict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 51.54398715456774, 'reliable': 48.45601284543227}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelperc(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/sample_structured.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the larger sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we preprocess the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import preprocessing_functions\n",
    "import cleaning_functions\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning took 12.140047073364258 seconds\n",
      "writing to csv took 0.5206699371337891 seconds\n",
      "cleaning took 12.753144025802612 seconds\n",
      "writing to csv took 0.5061330795288086 seconds\n",
      "cleaning took 10.977329015731812 seconds\n",
      "writing to csv took 0.45581698417663574 seconds\n",
      "cleaning took 9.846807718276978 seconds\n",
      "writing to csv took 0.41986608505249023 seconds\n",
      "cleaning took 9.785102844238281 seconds\n",
      "writing to csv took 0.4577157497406006 seconds\n",
      "cleaning took 10.401563882827759 seconds\n",
      "writing to csv took 0.47033214569091797 seconds\n"
     ]
    }
   ],
   "source": [
    "file_name = \"data/sample_preprocessed_ver_\" + datetime.today().strftime('%Y-%m-%d-%s') + \".csv\"\n",
    "meta_data = \"meta_data/preprocess_info.csv\"\n",
    "for chunck in pd.read_csv(\"data/sample_structured.csv\", chunksize=10000, index_col=0):\n",
    "    cleaning_functions.clean_dataframe(chunck)\n",
    "    chunck['content'] = chunck['content'].apply(preprocessing_functions.tokenizer())\n",
    "    chunck['content'] = chunck['content'].apply(preprocessing_functions.stopwords_remover())\n",
    "    chunck['content'] = chunck['content'].apply(preprocessing_functions.token_stemmer())\n",
    "    chunck['content'] = chunck['content'].apply(preprocessing_functions.list_converter())\n",
    "    start = time.time()\n",
    "    chunck.to_csv(file_name, mode='a')\n",
    "    end = time.time()\n",
    "    print(\"writing to csv took \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
