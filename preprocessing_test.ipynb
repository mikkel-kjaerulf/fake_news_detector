{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from cleantext import clean\n",
    "import pyarrow.feather as feather\n",
    "from multiprocessing import Pool\n",
    "import gc\n",
    "import nltk\n",
    "import itertools\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([\\d]{1,2}[\\/|\\-][\\d]{1,2}(?:[\\/|\\-][\\d]{2,4})?|[\\d]{2,4}[\\/|\\-][\\d]{1,2}[\\/|\\-][\\d]{1,2}|(?:january|february|march|april|may|june|july|august|september|october|november|december)[\\s][\\d]{1,2}[a-z][a-z](?:\\s[\\d]{2,4})|[\\d][\\d]\\w?\\w?\\sof\\s(?:january|february|march|april|may|june|july|august|september|october|november|december)(?:\\s[\\d]{2,4})?|(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s\\d\\d?\\w?\\w?,?(?:\\s\\d{2,4})?)\")\n",
    "def clean_string(st):\n",
    "    s1 = pattern.sub(\"date\",st)\n",
    "    return clean(s1, lower=True,\n",
    "                    no_line_breaks=True,\n",
    "                    no_emails=True,\n",
    "                    no_urls=True,\n",
    "                    no_numbers=True,\n",
    "                    no_punct=True,\n",
    "                    lang=\"en\",\n",
    "                    replace_with_number=\"num\",\n",
    "                    replace_with_email=\"email\",\n",
    "                    replace_with_url=\"url\")\n",
    "\n",
    "            \n",
    "\n",
    "def clean_dataframe(dataframe):\n",
    "    start = time.time()\n",
    "    dataframe['content'] = dataframe['content'].apply(clean_string)\n",
    "    end = time.time()\n",
    "    print(\"cleaning took \" + str(end - start) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_english_stopwords(stopwords):\n",
    "    def remove_stopwords(tokenlist):\n",
    "        return filter(lambda x : x not in stopwords, tokenlist)\n",
    "    return remove_stopwords\n",
    "\n",
    "def stem_tokens():\n",
    "    stemmer = PorterStemmer()\n",
    "    def stem_tokenlist(tokenlist):\n",
    "        return map(stemmer.stem, tokenlist)\n",
    "    return stem_tokenlist\n",
    "\n",
    "def tokenize():\n",
    "    def tokenize_text(s):\n",
    "        return list((map(nltk.word_tokenize, s)))\n",
    "    return tokenize_text\n",
    "\n",
    "def to_list():\n",
    "    def turn_to_list(it):\n",
    "        return list(it)\n",
    "    return turn_to_list\n",
    "\n",
    "def preprocess(dataframe):\n",
    "    # tokenize content column\n",
    "    #print(\"Tokenizing...\")\n",
    "    start = time.time()\n",
    "    dataframe['content'] = dataframe['content'].apply(nltk.word_tokenize)\n",
    "    end = time.time()\n",
    "    print(\"tokenizing took \" + str(end - start) + \" seconds\")\n",
    "    #tokens = list(itertools.chain.from_iterable(dataframe['content']))\n",
    "    #vocabulary = set(tokens)\n",
    "    # remove stopwords\n",
    "    start = time.time()\n",
    "    dataframe['content'] = dataframe['content'].apply(remove_english_stopwords(stopwords.words('english')))\n",
    "    end = time.time()\n",
    "    print(\"removing stopwords took \" + str(end - start) + \" seconds\")\n",
    "    #tokens_no_stopwords = list(itertools.chain.from_iterable(dataframe['content']))\n",
    "    #vocabulary_no_stopwords = set(tokens_no_stopwords)\n",
    "    #print(\"Reduction rate of removing stopwords: \" + str(1 - len(vocabulary_no_stopwords) / len(vocabulary)))\n",
    "    # stem tokens\n",
    "    start = time.time()\n",
    "    dataframe['content'] = dataframe['content'].apply(stem_tokens())\n",
    "    end = time.time()\n",
    "    print(\"stemming took \" + str(end - start) + \" seconds\")\n",
    "\n",
    "    start = time.time()\n",
    "    dataframe['content'] = dataframe['content'].apply(to_list())\n",
    "    end = time.time()\n",
    "    print(\"converting to list took\" + str(end - start) + \" seconds\")\n",
    "\n",
    "    #tokens_stem = list(itertools.chain.from_iterable(dataframe['content']))\n",
    "    #print(\"Stemmed tokens = \" + str(tokens_stem))\n",
    "    #vocabulary_stem = set(tokens_stem)\n",
    "    #print(\"Reduction rate of stemming: \" + str(1 - len(vocabulary_stem)/len(vocabulary_no_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7ff1b89e2a10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_tokens()([\"running\", \"runs\", \"running\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"([\\d]{1,2}[\\/|\\-][\\d]{1,2}(?:[\\/|\\-][\\d]{2,4})?|[\\d]{2,4}[\\/|\\-][\\d]{1,2}[\\/|\\-][\\d]{1,2}|(?:january|february|march|april|may|june|july|august|september|october|november|december)[\\s][\\d]{1,2}[a-z][a-z](?:\\s[\\d]{2,4})|[\\d][\\d]\\w?\\w?\\sof\\s(?:january|february|march|april|may|june|july|august|september|october|november|december)(?:\\s[\\d]{2,4})?|(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s\\d\\d?\\w?\\w?,?(?:\\s\\d{2,4})?)\")\n",
    "stemmer = PorterStemmer()\n",
    "def process_string(s):\n",
    "    s1 = pattern.sub(\"date\",s)\n",
    "    cleaned_string = clean(s1, lower=True,\n",
    "                no_line_breaks=True,\n",
    "                no_emails=True,\n",
    "                no_urls=True,\n",
    "                no_numbers=True,\n",
    "                lang=\"en\",\n",
    "                replace_with_number=\"num\",\n",
    "                replace_with_email=\"email\",\n",
    "                replace_with_url=\"url\")\n",
    "    #print(\"tokenizing...\")\n",
    "    tokens = nltk.word_tokenize(cleaned_string)\n",
    "    #print(\"removing stopwords...\")\n",
    "    tokens_no_stopwords = filter(lambda x : x not in stopwords.words('english'), tokens)\n",
    "    #print(\"stemming...\")\n",
    "    stem_tokens = list(map(stemmer.stem, tokens_no_stopwords))\n",
    "    return stem_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m chunck \u001b[39min\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdata/sample_STRUCTURED.csv\u001b[39m\u001b[39m\"\u001b[39m, chunksize\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[39m#print(\"cleaning...\")\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m#clean_dataframe(chunck)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39m#print(\"preprocessing...\")\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39m#preprocess(chunck)\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     chunck[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m chunck[\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(process_string)\n\u001b[1;32m     10\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     11\u001b[0m     chunck\u001b[39m.\u001b[39mto_csv(file_name, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 19\u001b[0m, in \u001b[0;36mprocess_string\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     17\u001b[0m tokens_no_stopwords \u001b[39m=\u001b[39m \u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m x : x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m), tokens)\n\u001b[1;32m     18\u001b[0m \u001b[39m#print(\"stemming...\")\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m stem_tokens \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(stemmer\u001b[39m.\u001b[39;49mstem, tokens_no_stopwords))\n\u001b[1;32m     20\u001b[0m \u001b[39mreturn\u001b[39;00m stem_tokens\n",
      "Cell \u001b[0;32mIn[11], line 17\u001b[0m, in \u001b[0;36mprocess_string.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m tokens \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mword_tokenize(cleaned_string)\n\u001b[1;32m     16\u001b[0m \u001b[39m#print(\"removing stopwords...\")\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m tokens_no_stopwords \u001b[39m=\u001b[39m \u001b[39mfilter\u001b[39m(\u001b[39mlambda\u001b[39;00m x : x \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m), tokens)\n\u001b[1;32m     18\u001b[0m \u001b[39m#print(\"stemming...\")\u001b[39;00m\n\u001b[1;32m     19\u001b[0m stem_tokens \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(stemmer\u001b[39m.\u001b[39mstem, tokens_no_stopwords))\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/nltk/corpus/reader/wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwords\u001b[39m(\u001b[39mself\u001b[39m, fileids\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_lines_startswith\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m     20\u001b[0m         line\n\u001b[0;32m---> 21\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m line_tokenize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw(fileids))\n\u001b[1;32m     22\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line\u001b[39m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[1;32m     23\u001b[0m     ]\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/nltk/corpus/reader/api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m    216\u001b[0m contents \u001b[39m=\u001b[39m []\n\u001b[1;32m    217\u001b[0m \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m fileids:\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(f) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m    219\u001b[0m         contents\u001b[39m.\u001b[39mappend(fp\u001b[39m.\u001b[39mread())\n\u001b[1;32m    220\u001b[0m \u001b[39mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/nltk/data.py:1167\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m, value, traceback):\n\u001b[0;32m-> 1167\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/nltk/data.py:1196\u001b[0m, in \u001b[0;36mSeekableUnicodeStreamReader.close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclose\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1193\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[39m    Close the underlying stream.\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1196\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mclose()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_name = \"data/sample_preprocessed_no_punct.csv\"\n",
    "with open(file_name, \"w\") as file:\n",
    "    pass\n",
    "for chunck in pd.read_csv(\"data/sample_STRUCTURED.csv\", chunksize=1000):\n",
    "    clean_dataframe(chunck)\n",
    "    preprocess(chunck)\n",
    "    start = time.time()\n",
    "    chunck.to_csv(file_name, mode='a')\n",
    "    end = time.time()\n",
    "    print(\"writing to csv took \" + str(end - start) + \" seconds\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/r8x5s5mn7jg12hs3c28wpg4c0000gn/T/ipykernel_3022/3757481934.py:1: DtypeWarning: Columns (1,2,3,13,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sample = pd.read_csv(\"data/sample_preprocessed.csv\")\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv(\"data/sample_preprocessed.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11467794</td>\n",
       "      <td>8027</td>\n",
       "      <td>9787368</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://query.nytimes.com/gst/fullpage.html?re...</td>\n",
       "      <td>['kasha', '--', 'audrey', 'sission', ',', 'lif...</td>\n",
       "      <td>2018-02-11 00:48:58.787555</td>\n",
       "      <td>2018-02-11 00:14:20.346838</td>\n",
       "      <td>2018-02-11 00:14:20.346871</td>\n",
       "      <td>Paid Notice: Deaths  KASHA, AUDREY SISSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['KASHA  AUDREY SISSION']</td>\n",
       "      <td>KASHA--Audrey Sission, a lifelong New Yorker, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4591569</td>\n",
       "      <td>8760</td>\n",
       "      <td>3009581</td>\n",
       "      <td>thinkprogress.org</td>\n",
       "      <td>political</td>\n",
       "      <td>https://thinkprogress.org/into-the-valley-of-d...</td>\n",
       "      <td>['``', 'forward', ',', 'light', 'brigad', '!',...</td>\n",
       "      <td>2017-11-18T20:01:27.400599</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Into The Valley Of Death Rode The 600, Into Th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Climate Change, #Climate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6162754</td>\n",
       "      <td>2521</td>\n",
       "      <td>4251195</td>\n",
       "      <td>truthandaction.org</td>\n",
       "      <td>bias</td>\n",
       "      <td>http://www.truthandaction.org/woman-thrown-off...</td>\n",
       "      <td>['woman', 'thrown', 'plane', 'said', 'hillari'...</td>\n",
       "      <td>2017-11-27T01:15:32.269834</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Woman Thrown Off Plane When She Said Hillary i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2542246</td>\n",
       "      <td>2019</td>\n",
       "      <td>1769246</td>\n",
       "      <td>ecowatch.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.ecowatch.com/cuban-province-well-o...</td>\n",
       "      <td>['cuban', 'provinc', 'well', 'way', 'num', '%'...</td>\n",
       "      <td>2017-11-10T11:18:44.524042</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Cuban Province Well on Its Way to 100% Renewab...</td>\n",
       "      <td>Guest Contributor, Sierra Club, Common Dreams,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['featured', 'renewables', 'business', 'cuba']</td>\n",
       "      <td>President Obama’s recent announcement that he ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3753783</td>\n",
       "      <td>4806</td>\n",
       "      <td>2429386</td>\n",
       "      <td>weeklystandard.com</td>\n",
       "      <td>political</td>\n",
       "      <td>http://www.weeklystandard.com/print/the-times-...</td>\n",
       "      <td>['new', 'york', 'time', 'greet', 'deleg', 'fro...</td>\n",
       "      <td>2017-11-13T18:09:27.760857</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>The Times Repeats Itself</td>\n",
       "      <td>To The Scrapbook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['The Scrapbook']</td>\n",
       "      <td>The New York Times greeted delegates with a fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2 Unnamed: 0.1 Unnamed: 0       id              domain  \\\n",
       "0           0.0     11467794       8027  9787368         nytimes.com   \n",
       "1           1.0      4591569       8760  3009581   thinkprogress.org   \n",
       "2           2.0      6162754       2521  4251195  truthandaction.org   \n",
       "3           3.0      2542246       2019  1769246        ecowatch.com   \n",
       "4           4.0      3753783       4806  2429386  weeklystandard.com   \n",
       "\n",
       "        type                                                url  \\\n",
       "0   reliable  https://query.nytimes.com/gst/fullpage.html?re...   \n",
       "1  political  https://thinkprogress.org/into-the-valley-of-d...   \n",
       "2       bias  http://www.truthandaction.org/woman-thrown-off...   \n",
       "3  political  https://www.ecowatch.com/cuban-province-well-o...   \n",
       "4  political  http://www.weeklystandard.com/print/the-times-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  ['kasha', '--', 'audrey', 'sission', ',', 'lif...   \n",
       "1  ['``', 'forward', ',', 'light', 'brigad', '!',...   \n",
       "2  ['woman', 'thrown', 'plane', 'said', 'hillari'...   \n",
       "3  ['cuban', 'provinc', 'well', 'way', 'num', '%'...   \n",
       "4  ['new', 'york', 'time', 'greet', 'deleg', 'fro...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2018-02-11 00:48:58.787555  2018-02-11 00:14:20.346838   \n",
       "1  2017-11-18T20:01:27.400599  2018-02-07 23:39:33.852671   \n",
       "2  2017-11-27T01:15:32.269834  2018-02-07 23:39:33.852671   \n",
       "3  2017-11-10T11:18:44.524042  2018-02-07 23:39:33.852671   \n",
       "4  2017-11-13T18:09:27.760857  2018-02-07 23:39:33.852671   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-11 00:14:20.346871   \n",
       "1  2018-02-07 23:39:33.852696   \n",
       "2  2018-02-07 23:39:33.852696   \n",
       "3  2018-02-07 23:39:33.852696   \n",
       "4  2018-02-07 23:39:33.852696   \n",
       "\n",
       "                                               title  \\\n",
       "0         Paid Notice: Deaths  KASHA, AUDREY SISSION   \n",
       "1  Into The Valley Of Death Rode The 600, Into Th...   \n",
       "2  Woman Thrown Off Plane When She Said Hillary i...   \n",
       "3  Cuban Province Well on Its Way to 100% Renewab...   \n",
       "4                           The Times Repeats Itself   \n",
       "\n",
       "                                             authors keywords  \\\n",
       "0                                                NaN      NaN   \n",
       "1                                                NaN      NaN   \n",
       "2                                                NaN      NaN   \n",
       "3  Guest Contributor, Sierra Club, Common Dreams,...      NaN   \n",
       "4                                   To The Scrapbook      NaN   \n",
       "\n",
       "                                    meta_keywords  \\\n",
       "0                       ['KASHA  AUDREY SISSION']   \n",
       "1                                            ['']   \n",
       "2                                            ['']   \n",
       "3  ['featured', 'renewables', 'business', 'cuba']   \n",
       "4                               ['The Scrapbook']   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  KASHA--Audrey Sission, a lifelong New Yorker, ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  President Obama’s recent announcement that he ...   \n",
       "4  The New York Times greeted delegates with a fr...   \n",
       "\n",
       "                        tags summary   source  \n",
       "0                        NaN     NaN  nytimes  \n",
       "1  #Climate Change, #Climate     NaN      NaN  \n",
       "2                        NaN     NaN      NaN  \n",
       "3                        NaN     NaN      NaN  \n",
       "4                        NaN     NaN      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>929394</th>\n",
       "      <td>929376.0</td>\n",
       "      <td>1658197</td>\n",
       "      <td>7865</td>\n",
       "      <td>849316</td>\n",
       "      <td>dailykos.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.dailykos.com/stories/2017/01/25/16...</td>\n",
       "      <td>['u.s.', 'naval', 'base', 'guantanamo', 'bay',...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Spokesman denies reports that Trump regime pla...</td>\n",
       "      <td>Backgroundurl Avatar_Large, Nickname, Joined, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929395</th>\n",
       "      <td>929377.0</td>\n",
       "      <td>880814</td>\n",
       "      <td>6934</td>\n",
       "      <td>690264</td>\n",
       "      <td>ecowatch.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.ecowatch.com/rooftop-solar-provide...</td>\n",
       "      <td>['cowri', 'collect', 'member', 'particip', 'ti...</td>\n",
       "      <td>2018-01-25 20:13:50.426130</td>\n",
       "      <td>2018-02-02 01:19:41.756632</td>\n",
       "      <td>2018-02-02 01:19:41.756664</td>\n",
       "      <td>Rooftop Solar Provides Net Benefits to All Nev...</td>\n",
       "      <td>Natural Resources Defense Council, Yes, The Co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['energy', 'renewables', 'featured']</td>\n",
       "      <td>The Natural Resources Defense Council (NRDC) a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929396</th>\n",
       "      <td>929378.0</td>\n",
       "      <td>11467044</td>\n",
       "      <td>7277</td>\n",
       "      <td>9786618</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://www.nytimes.com/2016/06/13/sports/hock...</td>\n",
       "      <td>['murray', ',', 'num', ',', 'ad', ':', '``', '...</td>\n",
       "      <td>2018-02-11 00:48:58.399133</td>\n",
       "      <td>2018-02-11 00:14:20.346838</td>\n",
       "      <td>2018-02-11 00:14:20.346871</td>\n",
       "      <td>Penguins Finish Off Sharks to Win Stanley Cup</td>\n",
       "      <td>David Pollak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hockey  Ice', 'Stanley Cup', 'Playoff Games'...</td>\n",
       "      <td>Pittsburgh won its second Stanley Cup in eight...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929397</th>\n",
       "      <td>929379.0</td>\n",
       "      <td>6510986</td>\n",
       "      <td>753</td>\n",
       "      <td>4640342</td>\n",
       "      <td>express.co.uk</td>\n",
       "      <td>rumor</td>\n",
       "      <td>https://www.express.co.uk/showbiz/tv-radio/726...</td>\n",
       "      <td>['num-year-old', 'actor', ',', 'former', 'east...</td>\n",
       "      <td>2017-11-27T01:14:33.570665</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>I’m A Celebrity 2016: Is Larry Lamb joining th...</td>\n",
       "      <td>Rory O'Connor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>LARRY LAMB is the latest celebrity to have agr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929398</th>\n",
       "      <td>929380.0</td>\n",
       "      <td>6794053</td>\n",
       "      <td>459</td>\n",
       "      <td>4934743</td>\n",
       "      <td>dailykos.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.dailykos.com/news/SameSexBinationa...</td>\n",
       "      <td>['leandra', 'english', 'file', 'suit', 'seek',...</td>\n",
       "      <td>2017-11-27T01:14:21.395055</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Daily Kos: SameSexBinationalCouples</td>\n",
       "      <td>Happy Cog Studios - Http, Www.Happycog.Com, Da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Next</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.2 Unnamed: 0.1 Unnamed: 0       id         domain  \\\n",
       "929394      929376.0      1658197       7865   849316   dailykos.com   \n",
       "929395      929377.0       880814       6934   690264   ecowatch.com   \n",
       "929396      929378.0     11467044       7277  9786618    nytimes.com   \n",
       "929397      929379.0      6510986        753  4640342  express.co.uk   \n",
       "929398      929380.0      6794053        459  4934743   dailykos.com   \n",
       "\n",
       "             type                                                url  \\\n",
       "929394  political  https://www.dailykos.com/stories/2017/01/25/16...   \n",
       "929395  political  https://www.ecowatch.com/rooftop-solar-provide...   \n",
       "929396   reliable  https://www.nytimes.com/2016/06/13/sports/hock...   \n",
       "929397      rumor  https://www.express.co.uk/showbiz/tv-radio/726...   \n",
       "929398  political  https://www.dailykos.com/news/SameSexBinationa...   \n",
       "\n",
       "                                                  content  \\\n",
       "929394  ['u.s.', 'naval', 'base', 'guantanamo', 'bay',...   \n",
       "929395  ['cowri', 'collect', 'member', 'particip', 'ti...   \n",
       "929396  ['murray', ',', 'num', ',', 'ad', ':', '``', '...   \n",
       "929397  ['num-year-old', 'actor', ',', 'former', 'east...   \n",
       "929398  ['leandra', 'english', 'file', 'suit', 'seek',...   \n",
       "\n",
       "                        scraped_at                 inserted_at  \\\n",
       "929394  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "929395  2018-01-25 20:13:50.426130  2018-02-02 01:19:41.756632   \n",
       "929396  2018-02-11 00:48:58.399133  2018-02-11 00:14:20.346838   \n",
       "929397  2017-11-27T01:14:33.570665  2018-02-07 23:39:33.852671   \n",
       "929398  2017-11-27T01:14:21.395055  2018-02-07 23:39:33.852671   \n",
       "\n",
       "                        updated_at  \\\n",
       "929394  2018-02-02 01:19:41.756664   \n",
       "929395  2018-02-02 01:19:41.756664   \n",
       "929396  2018-02-11 00:14:20.346871   \n",
       "929397  2018-02-07 23:39:33.852696   \n",
       "929398  2018-02-07 23:39:33.852696   \n",
       "\n",
       "                                                    title  \\\n",
       "929394  Spokesman denies reports that Trump regime pla...   \n",
       "929395  Rooftop Solar Provides Net Benefits to All Nev...   \n",
       "929396      Penguins Finish Off Sharks to Win Stanley Cup   \n",
       "929397  I’m A Celebrity 2016: Is Larry Lamb joining th...   \n",
       "929398                Daily Kos: SameSexBinationalCouples   \n",
       "\n",
       "                                                  authors keywords  \\\n",
       "929394  Backgroundurl Avatar_Large, Nickname, Joined, ...      NaN   \n",
       "929395  Natural Resources Defense Council, Yes, The Co...      NaN   \n",
       "929396                                       David Pollak      NaN   \n",
       "929397                                      Rory O'Connor      NaN   \n",
       "929398  Happy Cog Studios - Http, Www.Happycog.Com, Da...      NaN   \n",
       "\n",
       "                                            meta_keywords  \\\n",
       "929394                                               ['']   \n",
       "929395               ['energy', 'renewables', 'featured']   \n",
       "929396  ['Hockey  Ice', 'Stanley Cup', 'Playoff Games'...   \n",
       "929397                                               ['']   \n",
       "929398                                               ['']   \n",
       "\n",
       "                                         meta_description  tags summary  \\\n",
       "929394                                                NaN   NaN     NaN   \n",
       "929395  The Natural Resources Defense Council (NRDC) a...   NaN     NaN   \n",
       "929396  Pittsburgh won its second Stanley Cup in eight...   NaN     NaN   \n",
       "929397  LARRY LAMB is the latest celebrity to have agr...   NaN     NaN   \n",
       "929398                                                NaN  Next     NaN   \n",
       "\n",
       "         source  \n",
       "929394      NaN  \n",
       "929395      NaN  \n",
       "929396  nytimes  \n",
       "929397      NaN  \n",
       "929398      NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d82b2e002de3f5f2748faab7eed39a54b7eae736eec0eed65c518ce11052f6ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
