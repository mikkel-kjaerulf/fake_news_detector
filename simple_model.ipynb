{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  # reading csv files\n",
    "import pandas as pd # data science\n",
    "import numpy as np  # data science\n",
    "from sklearn.model_selection import train_test_split    # splitting the data\n",
    "import itertools    # getting a list of all words from a dataframe\n",
    "from collections import Counter # for getting number of occurences of words\n",
    "import regex as re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gj/r8x5s5mn7jg12hs3c28wpg4c0000gn/T/ipykernel_18928/3667402737.py:1: DtypeWarning: Columns (1,2,3,13,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(\"data/sample_preprocessed_no_punct.csv\")\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(\"data/sample_preprocessed_no_punct.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11467794</td>\n",
       "      <td>8027</td>\n",
       "      <td>9787368</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://query.nytimes.com/gst/fullpage.html?re...</td>\n",
       "      <td>['kashaaudrey', 'sission', 'lifelong', 'new', ...</td>\n",
       "      <td>2018-02-11 00:48:58.787555</td>\n",
       "      <td>2018-02-11 00:14:20.346838</td>\n",
       "      <td>2018-02-11 00:14:20.346871</td>\n",
       "      <td>Paid Notice: Deaths  KASHA, AUDREY SISSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['KASHA  AUDREY SISSION']</td>\n",
       "      <td>KASHA--Audrey Sission, a lifelong New Yorker, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4591569</td>\n",
       "      <td>8760</td>\n",
       "      <td>3009581</td>\n",
       "      <td>thinkprogress.org</td>\n",
       "      <td>political</td>\n",
       "      <td>https://thinkprogress.org/into-the-valley-of-d...</td>\n",
       "      <td>['forward', 'light', 'brigadewa', 'man', 'dism...</td>\n",
       "      <td>2017-11-18T20:01:27.400599</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Into The Valley Of Death Rode The 600, Into Th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Climate Change, #Climate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6162754</td>\n",
       "      <td>2521</td>\n",
       "      <td>4251195</td>\n",
       "      <td>truthandaction.org</td>\n",
       "      <td>bias</td>\n",
       "      <td>http://www.truthandaction.org/woman-thrown-off...</td>\n",
       "      <td>['woman', 'thrown', 'plane', 'said', 'hillari'...</td>\n",
       "      <td>2017-11-27T01:15:32.269834</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Woman Thrown Off Plane When She Said Hillary i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2542246</td>\n",
       "      <td>2019</td>\n",
       "      <td>1769246</td>\n",
       "      <td>ecowatch.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.ecowatch.com/cuban-province-well-o...</td>\n",
       "      <td>['cuban', 'provinc', 'well', 'way', 'num', 're...</td>\n",
       "      <td>2017-11-10T11:18:44.524042</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Cuban Province Well on Its Way to 100% Renewab...</td>\n",
       "      <td>Guest Contributor, Sierra Club, Common Dreams,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['featured', 'renewables', 'business', 'cuba']</td>\n",
       "      <td>President Obama’s recent announcement that he ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3753783</td>\n",
       "      <td>4806</td>\n",
       "      <td>2429386</td>\n",
       "      <td>weeklystandard.com</td>\n",
       "      <td>political</td>\n",
       "      <td>http://www.weeklystandard.com/print/the-times-...</td>\n",
       "      <td>['new', 'york', 'time', 'greet', 'deleg', 'fro...</td>\n",
       "      <td>2017-11-13T18:09:27.760857</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>The Times Repeats Itself</td>\n",
       "      <td>To The Scrapbook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['The Scrapbook']</td>\n",
       "      <td>The New York Times greeted delegates with a fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2 Unnamed: 0.1 Unnamed: 0       id              domain  \\\n",
       "0           0.0     11467794       8027  9787368         nytimes.com   \n",
       "1           1.0      4591569       8760  3009581   thinkprogress.org   \n",
       "2           2.0      6162754       2521  4251195  truthandaction.org   \n",
       "3           3.0      2542246       2019  1769246        ecowatch.com   \n",
       "4           4.0      3753783       4806  2429386  weeklystandard.com   \n",
       "\n",
       "        type                                                url  \\\n",
       "0   reliable  https://query.nytimes.com/gst/fullpage.html?re...   \n",
       "1  political  https://thinkprogress.org/into-the-valley-of-d...   \n",
       "2       bias  http://www.truthandaction.org/woman-thrown-off...   \n",
       "3  political  https://www.ecowatch.com/cuban-province-well-o...   \n",
       "4  political  http://www.weeklystandard.com/print/the-times-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  ['kashaaudrey', 'sission', 'lifelong', 'new', ...   \n",
       "1  ['forward', 'light', 'brigadewa', 'man', 'dism...   \n",
       "2  ['woman', 'thrown', 'plane', 'said', 'hillari'...   \n",
       "3  ['cuban', 'provinc', 'well', 'way', 'num', 're...   \n",
       "4  ['new', 'york', 'time', 'greet', 'deleg', 'fro...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2018-02-11 00:48:58.787555  2018-02-11 00:14:20.346838   \n",
       "1  2017-11-18T20:01:27.400599  2018-02-07 23:39:33.852671   \n",
       "2  2017-11-27T01:15:32.269834  2018-02-07 23:39:33.852671   \n",
       "3  2017-11-10T11:18:44.524042  2018-02-07 23:39:33.852671   \n",
       "4  2017-11-13T18:09:27.760857  2018-02-07 23:39:33.852671   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-11 00:14:20.346871   \n",
       "1  2018-02-07 23:39:33.852696   \n",
       "2  2018-02-07 23:39:33.852696   \n",
       "3  2018-02-07 23:39:33.852696   \n",
       "4  2018-02-07 23:39:33.852696   \n",
       "\n",
       "                                               title  \\\n",
       "0         Paid Notice: Deaths  KASHA, AUDREY SISSION   \n",
       "1  Into The Valley Of Death Rode The 600, Into Th...   \n",
       "2  Woman Thrown Off Plane When She Said Hillary i...   \n",
       "3  Cuban Province Well on Its Way to 100% Renewab...   \n",
       "4                           The Times Repeats Itself   \n",
       "\n",
       "                                             authors keywords  \\\n",
       "0                                                NaN      NaN   \n",
       "1                                                NaN      NaN   \n",
       "2                                                NaN      NaN   \n",
       "3  Guest Contributor, Sierra Club, Common Dreams,...      NaN   \n",
       "4                                   To The Scrapbook      NaN   \n",
       "\n",
       "                                    meta_keywords  \\\n",
       "0                       ['KASHA  AUDREY SISSION']   \n",
       "1                                            ['']   \n",
       "2                                            ['']   \n",
       "3  ['featured', 'renewables', 'business', 'cuba']   \n",
       "4                               ['The Scrapbook']   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  KASHA--Audrey Sission, a lifelong New Yorker, ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  President Obama’s recent announcement that he ...   \n",
       "4  The New York Times greeted delegates with a fr...   \n",
       "\n",
       "                        tags summary   source  \n",
       "0                        NaN     NaN  nytimes  \n",
       "1  #Climate Change, #Climate     NaN      NaN  \n",
       "2                        NaN     NaN      NaN  \n",
       "3                        NaN     NaN      NaN  \n",
       "4                        NaN     NaN      NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['kashaaudrey', 'sission', 'lifelong', 'new', 'yorker', 'born', 'decemb', 'num', 'num', 'die', 'june', 'num', 'num', 'daughter', 'late', 'helen', 'sissoncerussi', 'theodor', 'r', 'sisson', 'mother', 'late', 'matthew', 'p', 'kasha', 'sister', 'b', 'peter', 'cerussi', 'maxin', 'l', 'sisson', 'gloria', 'cerussi', 'gravesid', 'servic', 'friday', 'june', 'num', '11am', 'warwick', 'cemeteri', 'warwick', 'ny', 'contribut', 'memori', 'anim', 'welfar', 'group', 'choic', 'would', 'appreci', 'date']\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data['content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"\\w+\")\n",
    "def string_to_list(s):\n",
    "    return pattern.findall(s)\n",
    "raw_data['content'] = raw_data['content'].apply(string_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data[raw_data['type'].isnull() == False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS IS JUST TEMPORARY - HERE WE NEED TO DECIDE WHAT TO DO ABOUT THE FACT THAT NOT ALL ARTICLES ARE EITHER 'RELIABLE' OR 'FAKE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data[(data['type'] == 'fake') | (data['type'] == 'reliable')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621916"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>inserted_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>meta_keywords</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>tags</th>\n",
       "      <th>summary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11467794</td>\n",
       "      <td>8027</td>\n",
       "      <td>9787368</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>reliable</td>\n",
       "      <td>https://query.nytimes.com/gst/fullpage.html?re...</td>\n",
       "      <td>[kashaaudrey, sission, lifelong, new, yorker, ...</td>\n",
       "      <td>2018-02-11 00:48:58.787555</td>\n",
       "      <td>2018-02-11 00:14:20.346838</td>\n",
       "      <td>2018-02-11 00:14:20.346871</td>\n",
       "      <td>Paid Notice: Deaths  KASHA, AUDREY SISSION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['KASHA  AUDREY SISSION']</td>\n",
       "      <td>KASHA--Audrey Sission, a lifelong New Yorker, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4591569</td>\n",
       "      <td>8760</td>\n",
       "      <td>3009581</td>\n",
       "      <td>thinkprogress.org</td>\n",
       "      <td>political</td>\n",
       "      <td>https://thinkprogress.org/into-the-valley-of-d...</td>\n",
       "      <td>[forward, light, brigadewa, man, dismayd, tho,...</td>\n",
       "      <td>2017-11-18T20:01:27.400599</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Into The Valley Of Death Rode The 600, Into Th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#Climate Change, #Climate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6162754</td>\n",
       "      <td>2521</td>\n",
       "      <td>4251195</td>\n",
       "      <td>truthandaction.org</td>\n",
       "      <td>bias</td>\n",
       "      <td>http://www.truthandaction.org/woman-thrown-off...</td>\n",
       "      <td>[woman, thrown, plane, said, hillari, b]</td>\n",
       "      <td>2017-11-27T01:15:32.269834</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Woman Thrown Off Plane When She Said Hillary i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2542246</td>\n",
       "      <td>2019</td>\n",
       "      <td>1769246</td>\n",
       "      <td>ecowatch.com</td>\n",
       "      <td>political</td>\n",
       "      <td>https://www.ecowatch.com/cuban-province-well-o...</td>\n",
       "      <td>[cuban, provinc, well, way, num, renew, energi]</td>\n",
       "      <td>2017-11-10T11:18:44.524042</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>Cuban Province Well on Its Way to 100% Renewab...</td>\n",
       "      <td>Guest Contributor, Sierra Club, Common Dreams,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['featured', 'renewables', 'business', 'cuba']</td>\n",
       "      <td>President Obama’s recent announcement that he ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3753783</td>\n",
       "      <td>4806</td>\n",
       "      <td>2429386</td>\n",
       "      <td>weeklystandard.com</td>\n",
       "      <td>political</td>\n",
       "      <td>http://www.weeklystandard.com/print/the-times-...</td>\n",
       "      <td>[new, york, time, greet, deleg, frontpag, scoo...</td>\n",
       "      <td>2017-11-13T18:09:27.760857</td>\n",
       "      <td>2018-02-07 23:39:33.852671</td>\n",
       "      <td>2018-02-07 23:39:33.852696</td>\n",
       "      <td>The Times Repeats Itself</td>\n",
       "      <td>To The Scrapbook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['The Scrapbook']</td>\n",
       "      <td>The New York Times greeted delegates with a fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2 Unnamed: 0.1 Unnamed: 0       id              domain  \\\n",
       "0           0.0     11467794       8027  9787368         nytimes.com   \n",
       "1           1.0      4591569       8760  3009581   thinkprogress.org   \n",
       "2           2.0      6162754       2521  4251195  truthandaction.org   \n",
       "3           3.0      2542246       2019  1769246        ecowatch.com   \n",
       "4           4.0      3753783       4806  2429386  weeklystandard.com   \n",
       "\n",
       "        type                                                url  \\\n",
       "0   reliable  https://query.nytimes.com/gst/fullpage.html?re...   \n",
       "1  political  https://thinkprogress.org/into-the-valley-of-d...   \n",
       "2       bias  http://www.truthandaction.org/woman-thrown-off...   \n",
       "3  political  https://www.ecowatch.com/cuban-province-well-o...   \n",
       "4  political  http://www.weeklystandard.com/print/the-times-...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [kashaaudrey, sission, lifelong, new, yorker, ...   \n",
       "1  [forward, light, brigadewa, man, dismayd, tho,...   \n",
       "2           [woman, thrown, plane, said, hillari, b]   \n",
       "3    [cuban, provinc, well, way, num, renew, energi]   \n",
       "4  [new, york, time, greet, deleg, frontpag, scoo...   \n",
       "\n",
       "                   scraped_at                 inserted_at  \\\n",
       "0  2018-02-11 00:48:58.787555  2018-02-11 00:14:20.346838   \n",
       "1  2017-11-18T20:01:27.400599  2018-02-07 23:39:33.852671   \n",
       "2  2017-11-27T01:15:32.269834  2018-02-07 23:39:33.852671   \n",
       "3  2017-11-10T11:18:44.524042  2018-02-07 23:39:33.852671   \n",
       "4  2017-11-13T18:09:27.760857  2018-02-07 23:39:33.852671   \n",
       "\n",
       "                   updated_at  \\\n",
       "0  2018-02-11 00:14:20.346871   \n",
       "1  2018-02-07 23:39:33.852696   \n",
       "2  2018-02-07 23:39:33.852696   \n",
       "3  2018-02-07 23:39:33.852696   \n",
       "4  2018-02-07 23:39:33.852696   \n",
       "\n",
       "                                               title  \\\n",
       "0         Paid Notice: Deaths  KASHA, AUDREY SISSION   \n",
       "1  Into The Valley Of Death Rode The 600, Into Th...   \n",
       "2  Woman Thrown Off Plane When She Said Hillary i...   \n",
       "3  Cuban Province Well on Its Way to 100% Renewab...   \n",
       "4                           The Times Repeats Itself   \n",
       "\n",
       "                                             authors keywords  \\\n",
       "0                                                NaN      NaN   \n",
       "1                                                NaN      NaN   \n",
       "2                                                NaN      NaN   \n",
       "3  Guest Contributor, Sierra Club, Common Dreams,...      NaN   \n",
       "4                                   To The Scrapbook      NaN   \n",
       "\n",
       "                                    meta_keywords  \\\n",
       "0                       ['KASHA  AUDREY SISSION']   \n",
       "1                                            ['']   \n",
       "2                                            ['']   \n",
       "3  ['featured', 'renewables', 'business', 'cuba']   \n",
       "4                               ['The Scrapbook']   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  KASHA--Audrey Sission, a lifelong New Yorker, ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  President Obama’s recent announcement that he ...   \n",
       "4  The New York Times greeted delegates with a fr...   \n",
       "\n",
       "                        tags summary   source  \n",
       "0                        NaN     NaN  nytimes  \n",
       "1  #Climate Change, #Climate     NaN      NaN  \n",
       "2                        NaN     NaN      NaN  \n",
       "3                        NaN     NaN      NaN  \n",
       "4                        NaN     NaN      NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer=lambda x : x)\n",
    "X = vectorizer.fit_transform(data['content'])\n",
    "y = data['type']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data before representing our data as bag of words for naive bayes classifier in order to avoid statistics leaking into validation and testing dat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "head not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train\u001b[39m.\u001b[39;49mhead()\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/scipy/sparse/_base.py:771\u001b[0m, in \u001b[0;36mspmatrix.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetnnz()\n\u001b[1;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(attr \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: head not found"
     ]
    }
   ],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466437, 1364774)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466437"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_words(dataframe):\n",
    "    # get all words appearing in reliable articles\n",
    "    reliable_words = [word for list in list(itertools.chain(dataframe.loc[dataframe['type'] == 'reliable'].content)) for word in list]\n",
    "    # get all words appearing in fake articles\n",
    "    fake_words = [word for list in list(itertools.chain(dataframe.loc[dataframe['type'] == 'fake'].content)) for word in list]\n",
    "    # count words in both lists\n",
    "    count_reliable = Counter(reliable_words)\n",
    "    count_fake = Counter(fake_words)\n",
    "    return pd.DataFrame({'reliable': pd.Series(count_reliable), 'fake': pd.Series(count_fake)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = create_bag_of_words(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reliable</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000bq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000deg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0012712kai</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reliable  fake\n",
       "0                2.0   NaN\n",
       "00              18.0   3.0\n",
       "000bq            NaN   4.0\n",
       "000deg           NaN   2.0\n",
       "0012712kai       1.0   NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reliable</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>️truth</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>️ugggirl</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>️url</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>️wf</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>️win</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reliable  fake\n",
       "️truth         NaN   2.0\n",
       "️ugggirl       NaN   1.0\n",
       "️url           NaN   1.0\n",
       "️wf            NaN   1.0\n",
       "️win           NaN   1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reliable</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0500z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>051date0239</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>054date1258</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>054date4145</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0577n089112a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0577n089112b</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05a4820</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05pm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05th</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05vnum</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>061date29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>062date1d</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>062date2230</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>065date11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06am</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06date00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06date02290</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06date02291</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06date02292</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06pm</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0714date038th</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07182014p01ph</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>074892941date9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>077date25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>079date43</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07a</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07am</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07date00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07date95950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07may15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07pm</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>080date46</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>085date57</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>086571598x</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08date00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08date30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08pm</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08pt</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0900hr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>090date6d</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09am</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09date15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09date99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09h30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09madrid347</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                reliable  fake\n",
       "05                   2.0   NaN\n",
       "0500z                NaN   1.0\n",
       "051date0239          1.0   NaN\n",
       "054date1258          1.0   NaN\n",
       "054date4145          1.0   NaN\n",
       "0577n089112a         NaN   1.0\n",
       "0577n089112b         NaN   1.0\n",
       "05a4820              1.0   NaN\n",
       "05pm                 1.0   NaN\n",
       "05th                 NaN   2.0\n",
       "05vnum               NaN   1.0\n",
       "05x                  NaN   1.0\n",
       "06                   1.0   NaN\n",
       "061date29            1.0   NaN\n",
       "062date1d            2.0   NaN\n",
       "062date2230          1.0   NaN\n",
       "065date11            1.0   NaN\n",
       "06am                 2.0   NaN\n",
       "06date00             NaN   1.0\n",
       "06date02290          1.0   NaN\n",
       "06date02291          1.0   NaN\n",
       "06date02292          1.0   NaN\n",
       "06pm                 1.0   NaN\n",
       "06z                  NaN   1.0\n",
       "0714date038th        NaN   1.0\n",
       "07182014p01ph        NaN   1.0\n",
       "074892941date9       NaN  40.0\n",
       "077date25            1.0   NaN\n",
       "079date43            1.0   NaN\n",
       "07a                  NaN   1.0\n",
       "07am                 2.0   NaN\n",
       "07date00             2.0   NaN\n",
       "07date95950          NaN   1.0\n",
       "07may15              NaN   1.0\n",
       "07pm                 3.0   NaN\n",
       "080date46            1.0   NaN\n",
       "085date57            2.0   NaN\n",
       "086571598x           NaN   1.0\n",
       "08date00             2.0   NaN\n",
       "08date30             1.0   NaN\n",
       "08pm                 2.0   NaN\n",
       "08pt                 NaN   1.0\n",
       "09                   1.0   NaN\n",
       "0900hr               NaN   1.0\n",
       "090date6d            1.0   NaN\n",
       "09am                 4.0   NaN\n",
       "09date15             1.0   NaN\n",
       "09date99             NaN   4.0\n",
       "09h30                1.0   NaN\n",
       "09madrid347          NaN   1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.iloc[50:100]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace all NaN values with 0, and add 1 to all values in order for Naive Bayes to work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_train += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reliable</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>4343.0</td>\n",
       "      <td>1418.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>228.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>347.0</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaah</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reliable    fake\n",
       "a            4343.0  1418.0\n",
       "aa            228.0   110.0\n",
       "aaa           347.0   127.0\n",
       "aaaa            4.0     1.0\n",
       "aaaaaaaah       2.0     1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function, so we can apply the same steps to X_val and X_test\n",
    "def process_for_nb(dataframe):\n",
    "    dataframe = create_bag_of_words(dataframe)\n",
    "    dataframe = dataframe.fillna(0)\n",
    "    dataframe += 1\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = process_for_nb(X_val)\n",
    "X_test = process_for_nb(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word',\n",
    "                             preprocessor=None,\n",
    "                             stop_words='english',\n",
    "                             max_features=100)\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_train_vectorized = X_train_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [437703, 147169]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logreg \u001b[39m=\u001b[39m LogisticRegression()\n\u001b[0;32m----> 2\u001b[0m logreg\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1196\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[0;32m-> 1196\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1197\u001b[0m     X,\n\u001b[1;32m   1198\u001b[0m     y,\n\u001b[1;32m   1199\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1200\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[1;32m   1201\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1202\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1203\u001b[0m )\n\u001b[1;32m   1204\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1205\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/utils/validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [437703, 147169]"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nMultinomialNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m nb \u001b[39m=\u001b[39m MultinomialNB()\n\u001b[0;32m----> 2\u001b[0m nb\u001b[39m.\u001b[39;49mfit(X_train,y_train)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/naive_bayes.py:749\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m \n\u001b[1;32m    731\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 749\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[1;32m    750\u001b[0m _, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    752\u001b[0m labelbin \u001b[39m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/naive_bayes.py:583\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X_y\u001b[39m(\u001b[39mself\u001b[39m, X, y, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    582\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49mreset)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/utils/validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[0;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/fake_news/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nMultinomialNB does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Example of problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hey': 1, 'word': 1, 'donald': 2})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = Counter(['hey', 'word', 'donald', 'donald'])\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for word in count:\n",
    "    print(count[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'hey': 1, 'word': 1, 'donald': 4, 'win': 1, 'some': 1})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count2 = Counter(['win', 'some', 'donald', 'donald'])\n",
    "count + count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reliable</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hey</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>some</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>win</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reliable  fake\n",
       "donald       2.0   2.0\n",
       "hey          1.0   NaN\n",
       "some         NaN   1.0\n",
       "win          NaN   1.0\n",
       "word         1.0   NaN"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'reliable': pd.Series(count), 'fake': pd.Series(count2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [kashaaudrey, sission, lifelong, new, yorker, ...\n",
       "5         [market, news, thu, nov, num, num, num, am, ed...\n",
       "19        [articl, last, tuesday, chang, manag, chelsea,...\n",
       "24        [nathanael, chung, num, westfield, two, straig...\n",
       "30        [area, larger, home, larger, lot, typic, sight...\n",
       "                                ...                        \n",
       "649993    [strategi, play, campaign, work, deni, oppon, ...\n",
       "649998    [creat, powerpoint, present, document, go, fai...\n",
       "650003    [human, weapon, grip, import, documentari, exa...\n",
       "650009    [world, news, thu, nov, num, num, num, am, gmt...\n",
       "650011    [q, law, govern, instal, solar, panel, new, yo...\n",
       "Name: content, Length: 133693, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['type'] == 'reliable'].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliable_words = [word for list in (data.loc[data['type'] == 'reliable'].content) for word in list]\n",
    "fake_words = [word for list in (data.loc[data['type'] == 'fake'].content) for word in list]\n",
    "count_fake = Counter(fake_words)\n",
    "count_reliable = Counter(reliable_words)\n",
    "test = pd.DataFrame({'reliable': pd.Series(count_reliable), 'fake': pd.Series(count_fake)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reliable</th>\n",
       "      <th>fake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>5665.0</td>\n",
       "      <td>1866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>280.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>476.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaaaaah</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reliable    fake\n",
       "a            5665.0  1866.0\n",
       "aa            280.0   145.0\n",
       "aaa           476.0   159.0\n",
       "aaaa            3.0     NaN\n",
       "aaaaaaaah       1.0     NaN"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['donald', 'trump', 'donald']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r\"\\w+\")\n",
    "pattern.findall(\"'[donald', 'trump', 'donald]'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'berri': 693,\n",
       "         'dual': 287,\n",
       "         'role': 10992,\n",
       "         'author': 18631,\n",
       "         'particip': 5035,\n",
       "         'give': 21610,\n",
       "         'justic': 8707,\n",
       "         'awkwardli': 123,\n",
       "         'divid': 2825,\n",
       "         'person': 20268,\n",
       "         'first': 63234,\n",
       "         'half': 13320,\n",
       "         'book': 22273,\n",
       "         'deal': 18539,\n",
       "         'year': 120563,\n",
       "         'appoint': 4510,\n",
       "         'function': 2517,\n",
       "         'tradit': 8072,\n",
       "         'academ': 2112,\n",
       "         'historian': 1469,\n",
       "         'second': 23774,\n",
       "         'becom': 21161,\n",
       "         'necessarili': 1695,\n",
       "         'selfinterest': 142,\n",
       "         'memoirist': 28,\n",
       "         'unintend': 224,\n",
       "         'consequ': 2148,\n",
       "         'power': 21201,\n",
       "         'episod': 3448,\n",
       "         'commiss': 7656,\n",
       "         'histori': 13529,\n",
       "         'receiv': 48263,\n",
       "         'dispassion': 64,\n",
       "         'treatment': 4868,\n",
       "         'seemingli': 1230,\n",
       "         'minutia': 62,\n",
       "         'period': 8293,\n",
       "         'lengthi': 659,\n",
       "         'attent': 6451,\n",
       "         'photo': 41875,\n",
       "         'one': 116769,\n",
       "         'unexpect': 1170,\n",
       "         'revel': 1218,\n",
       "         'may': 42213,\n",
       "         'help': 32545,\n",
       "         'explain': 7579,\n",
       "         'problem': 16748,\n",
       "         'num': 873292,\n",
       "         'success': 10940,\n",
       "         'persuad': 1895,\n",
       "         'clinton': 15492,\n",
       "         'administr': 16198,\n",
       "         'editor': 10376,\n",
       "         'alfr': 618,\n",
       "         'knopf': 382,\n",
       "         'victoria': 1175,\n",
       "         'wilson': 2754,\n",
       "         'open': 29676,\n",
       "         'seat': 6340,\n",
       "         'could': 54380,\n",
       "         'becam': 11064,\n",
       "         'absorb': 1073,\n",
       "         'insidebasebal': 2,\n",
       "         'like': 95983,\n",
       "         'lost': 11625,\n",
       "         'perspect': 1805,\n",
       "         'much': 36346,\n",
       "         'reason': 12093,\n",
       "         'reader': 3700,\n",
       "         'want': 42026,\n",
       "         'need': 32803,\n",
       "         'know': 31328,\n",
       "         'given': 11843,\n",
       "         'battl': 5724,\n",
       "         'liber': 4149,\n",
       "         'conserv': 7510,\n",
       "         'name': 22574,\n",
       "         'next': 27096,\n",
       "         'staff': 7975,\n",
       "         'director': 22065,\n",
       "         'outset': 224,\n",
       "         'contrast': 2746,\n",
       "         'revil': 87,\n",
       "         'senat': 17297,\n",
       "         'harri': 3990,\n",
       "         'f': 3621,\n",
       "         'byrd': 347,\n",
       "         'sr': 497,\n",
       "         'virginia': 3362,\n",
       "         'vehicl': 5056,\n",
       "         'witch': 401,\n",
       "         'hunt': 2343,\n",
       "         'worst': 2962,\n",
       "         'member': 25802,\n",
       "         'went': 14003,\n",
       "         'alabama': 1431,\n",
       "         'investig': 14580,\n",
       "         'violat': 4297,\n",
       "         'vote': 19112,\n",
       "         'right': 35352,\n",
       "         'stay': 9951,\n",
       "         'air': 9383,\n",
       "         'forc': 21479,\n",
       "         'base': 16539,\n",
       "         'everi': 21290,\n",
       "         'local': 13867,\n",
       "         'hotel': 8057,\n",
       "         'segreg': 448,\n",
       "         'testimoni': 1774,\n",
       "         'heard': 5492,\n",
       "         'earli': 17627,\n",
       "         'day': 50543,\n",
       "         'contain': 4256,\n",
       "         'horror': 1279,\n",
       "         'capabl': 1950,\n",
       "         'shame': 1068,\n",
       "         'nation': 39989,\n",
       "         'black': 15632,\n",
       "         'veteran': 4394,\n",
       "         'instanc': 3486,\n",
       "         'shot': 10787,\n",
       "         'back': 39418,\n",
       "         'paralyz': 311,\n",
       "         'polic': 21209,\n",
       "         'chief': 17054,\n",
       "         'deni': 4581,\n",
       "         'armi': 6899,\n",
       "         'pension': 2225,\n",
       "         'supposedli': 547,\n",
       "         'provok': 693,\n",
       "         'attack': 16142,\n",
       "         'anyway': 1444,\n",
       "         'long': 27156,\n",
       "         'fuller': 435,\n",
       "         'deeper': 1075,\n",
       "         'account': 12000,\n",
       "         'commission': 2753,\n",
       "         'handl': 4653,\n",
       "         'physic': 4397,\n",
       "         'polit': 25895,\n",
       "         'risk': 9057,\n",
       "         'find': 21009,\n",
       "         'fact': 10595,\n",
       "         'lethal': 420,\n",
       "         'hostil': 1200,\n",
       "         'environ': 3218,\n",
       "         'intermitt': 217,\n",
       "         'particular': 4090,\n",
       "         'rev': 1885,\n",
       "         'theodor': 435,\n",
       "         'hesburgh': 7,\n",
       "         'presid': 47483,\n",
       "         'notr': 680,\n",
       "         'dame': 824,\n",
       "         'leap': 928,\n",
       "         'vividli': 241,\n",
       "         'dryli': 71,\n",
       "         'duti': 2525,\n",
       "         'lose': 8071,\n",
       "         'temper': 572,\n",
       "         'hear': 9212,\n",
       "         'school': 34759,\n",
       "         'desegreg': 79,\n",
       "         'maryland': 1215,\n",
       "         'father': 15422,\n",
       "         'declar': 4509,\n",
       "         'counti': 10575,\n",
       "         'commun': 18818,\n",
       "         'drag': 1451,\n",
       "         'kick': 2532,\n",
       "         'scream': 1132,\n",
       "         'us': 43077,\n",
       "         'constitut': 4393,\n",
       "         'newslett': 94787,\n",
       "         'sign': 77773,\n",
       "         'continu': 111593,\n",
       "         'read': 105457,\n",
       "         'main': 100143,\n",
       "         'stori': 109932,\n",
       "         'pleas': 96319,\n",
       "         'verifi': 31411,\n",
       "         'your': 41318,\n",
       "         'robot': 31733,\n",
       "         'click': 33040,\n",
       "         'box': 35818,\n",
       "         'invalid': 30958,\n",
       "         'email': 41779,\n",
       "         'address': 37972,\n",
       "         'reenter': 30864,\n",
       "         'must': 42605,\n",
       "         'select': 36183,\n",
       "         'subscrib': 63754,\n",
       "         'agre': 40599,\n",
       "         'occasion': 33242,\n",
       "         'updat': 34981,\n",
       "         'special': 40726,\n",
       "         'offer': 53105,\n",
       "         'new': 191633,\n",
       "         'york': 111234,\n",
       "         'timess': 30723,\n",
       "         'product': 49506,\n",
       "         'servic': 56407,\n",
       "         'thank': 35692,\n",
       "         'error': 33374,\n",
       "         'occur': 34373,\n",
       "         'tri': 59933,\n",
       "         'later': 48107,\n",
       "         'view': 45686,\n",
       "         'time': 118484,\n",
       "         'still': 34965,\n",
       "         'recount': 1442,\n",
       "         'report': 40184,\n",
       "         'impact': 4932,\n",
       "         'feel': 19194,\n",
       "         'less': 19365,\n",
       "         'rather': 9193,\n",
       "         'far': 16100,\n",
       "         'shorterliv': 2,\n",
       "         'bodi': 8862,\n",
       "         'kerner': 17,\n",
       "         'formal': 2571,\n",
       "         'known': 13413,\n",
       "         'advisori': 962,\n",
       "         'civil': 6034,\n",
       "         'disord': 1243,\n",
       "         'left': 21143,\n",
       "         'behind': 10712,\n",
       "         'clearer': 308,\n",
       "         'memor': 1000,\n",
       "         'legaci': 1849,\n",
       "         'warn': 6060,\n",
       "         'move': 25158,\n",
       "         'toward': 8875,\n",
       "         'two': 67563,\n",
       "         'societi': 7152,\n",
       "         'white': 20496,\n",
       "         'separ': 5429,\n",
       "         'unequ': 123,\n",
       "         'closer': 2776,\n",
       "         'present': 11400,\n",
       "         'disput': 3102,\n",
       "         'foe': 311,\n",
       "         'signific': 5289,\n",
       "         'ronald': 1277,\n",
       "         'reagan': 1561,\n",
       "         'bask': 154,\n",
       "         'posthum': 131,\n",
       "         'bipartisan': 762,\n",
       "         'glow': 726,\n",
       "         'instruct': 1960,\n",
       "         'remind': 3281,\n",
       "         'divis': 6375,\n",
       "         'racial': 1981,\n",
       "         'practic': 10001,\n",
       "         'anticip': 1765,\n",
       "         'georg': 7723,\n",
       "         'h': 3791,\n",
       "         'w': 4957,\n",
       "         'bush': 14348,\n",
       "         'nomin': 3279,\n",
       "         'clarenc': 300,\n",
       "         'thoma': 6005,\n",
       "         'suprem': 4683,\n",
       "         'court': 22036,\n",
       "         'decad': 10302,\n",
       "         'instal': 4034,\n",
       "         'chairman': 8136,\n",
       "         'pendleton': 128,\n",
       "         'jr': 4717,\n",
       "         'oppos': 4277,\n",
       "         'agenda': 1920,\n",
       "         'affirm': 967,\n",
       "         'action': 9623,\n",
       "         'offici': 34427,\n",
       "         'describ': 9727,\n",
       "         'inherit': 776,\n",
       "         'pocket': 1495,\n",
       "         'renegad': 126,\n",
       "         'clean': 3979,\n",
       "         'budget': 7371,\n",
       "         'drastic': 577,\n",
       "         'cut': 14348,\n",
       "         'would': 103859,\n",
       "         'discern': 352,\n",
       "         'might': 21883,\n",
       "         'benefit': 8704,\n",
       "         'explan': 1432,\n",
       "         'omit': 343,\n",
       "         'altogeth': 676,\n",
       "         'style': 5931,\n",
       "         'scoresettl': 14,\n",
       "         'washington': 16727,\n",
       "         'memoir': 1342,\n",
       "         'reduc': 7008,\n",
       "         'antagonist': 115,\n",
       "         'linda': 1145,\n",
       "         'chavez': 716,\n",
       "         'abigail': 199,\n",
       "         'thernstrom': 19,\n",
       "         'michael': 10913,\n",
       "         'horowitz': 299,\n",
       "         'twodimension': 52,\n",
       "         'caricatur': 250,\n",
       "         'peopl': 75080,\n",
       "         'mindless': 67,\n",
       "         'enemi': 1987,\n",
       "         'equal': 4168,\n",
       "         'review': 9361,\n",
       "         'life': 25804,\n",
       "         'public': 28349,\n",
       "         'behalf': 1568,\n",
       "         'mari': 4373,\n",
       "         'franc': 6163,\n",
       "         'deserv': 2098,\n",
       "         'mani': 50108,\n",
       "         'accolad': 122,\n",
       "         'evid': 7633,\n",
       "         'wrong': 5279,\n",
       "         'tell': 13887,\n",
       "         'obvious': 2126,\n",
       "         'matter': 10015,\n",
       "         'deepli': 2912,\n",
       "         'els': 6226,\n",
       "         'privat': 12738,\n",
       "         'differ': 20168,\n",
       "         'lui': 715,\n",
       "         'benvenist': 13,\n",
       "         'martin': 4959,\n",
       "         'carnoy': 8,\n",
       "         'richard': 6768,\n",
       "         'rothstein': 54,\n",
       "         'pp': 361,\n",
       "         'routledgefalm': 1,\n",
       "         'paper': 6877,\n",
       "         'educ': 11339,\n",
       "         'reform': 4722,\n",
       "         'swamp': 431,\n",
       "         'contenti': 594,\n",
       "         'issu': 22437,\n",
       "         'simplist': 129,\n",
       "         'answer': 6929,\n",
       "         'wait': 7810,\n",
       "         'suck': 380,\n",
       "         'unwari': 15,\n",
       "         'among': 20013,\n",
       "         'heat': 4290,\n",
       "         'idea': 11610,\n",
       "         'provid': 19198,\n",
       "         'parent': 10703,\n",
       "         'choic': 6504,\n",
       "         'voucher': 404,\n",
       "         'propon': 503,\n",
       "         'field': 11659,\n",
       "         'number': 20065,\n",
       "         'argument': 3426,\n",
       "         'notion': 1844,\n",
       "         'advanc': 5944,\n",
       "         'economist': 2802,\n",
       "         'milton': 390,\n",
       "         'friedman': 968,\n",
       "         'argu': 6990,\n",
       "         'deliv': 5940,\n",
       "         'qualiti': 4275,\n",
       "         'cost': 15199,\n",
       "         'today': 19264,\n",
       "         'advoc': 3753,\n",
       "         'see': 30762,\n",
       "         'competit': 6267,\n",
       "         'best': 20270,\n",
       "         'way': 41888,\n",
       "         'improv': 8136,\n",
       "         'contend': 2601,\n",
       "         'abandon': 2512,\n",
       "         'system': 18624,\n",
       "         'break': 8147,\n",
       "         'wall': 10350,\n",
       "         'church': 11329,\n",
       "         'state': 81210,\n",
       "         'expert': 7091,\n",
       "         'world': 39591,\n",
       "         'bank': 20372,\n",
       "         'professor': 8000,\n",
       "         'econom': 12199,\n",
       "         'stanford': 1188,\n",
       "         'univers': 26137,\n",
       "         'former': 23042,\n",
       "         'columnist': 1376,\n",
       "         'respect': 6141,\n",
       "         'wade': 1024,\n",
       "         'debat': 7667,\n",
       "         'set': 24031,\n",
       "         'apart': 9016,\n",
       "         'lay': 2213,\n",
       "         'fairli': 1352,\n",
       "         'actual': 9189,\n",
       "         'test': 12353,\n",
       "         'theori': 2432,\n",
       "         'result': 14782,\n",
       "         'research': 14729,\n",
       "         'without': 18721,\n",
       "         'make': 61220,\n",
       "         'grandios': 139,\n",
       "         'claim': 9442,\n",
       "         'et': 1607,\n",
       "         'al': 4902,\n",
       "         'say': 65826,\n",
       "         'show': 43639,\n",
       "         'littl': 21920,\n",
       "         'origin': 9209,\n",
       "         'visit': 11697,\n",
       "         'sinc': 31724,\n",
       "         'finish': 7732,\n",
       "         'advertis': 66777,\n",
       "         'case': 25635,\n",
       "         'studi': 15462,\n",
       "         'eight': 6963,\n",
       "         'california': 8073,\n",
       "         'form': 10009,\n",
       "         'heart': 8562,\n",
       "         'pillar': 430,\n",
       "         'assert': 2394,\n",
       "         'organ': 16665,\n",
       "         'flexibl': 1154,\n",
       "         'goe': 5620,\n",
       "         'compet': 4039,\n",
       "         'anoth': 28203,\n",
       "         'lead': 20290,\n",
       "         'higher': 7310,\n",
       "         'student': 18017,\n",
       "         'achiev': 4403,\n",
       "         'magic': 2427,\n",
       "         'marketplac': 731,\n",
       "         'trap': 1332,\n",
       "         'bureaucrat': 504,\n",
       "         'hell': 2160,\n",
       "         'determin': 5957,\n",
       "         'teach': 4219,\n",
       "         'usual': 6743,\n",
       "         'high': 19889,\n",
       "         'imposs': 2396,\n",
       "         'govern': 37077,\n",
       "         'incompet': 271,\n",
       "         'predict': 4093,\n",
       "         'found': 23248,\n",
       "         'someth': 17536,\n",
       "         'turn': 21844,\n",
       "         'shape': 4011,\n",
       "         'cultur': 10057,\n",
       "         'around': 25596,\n",
       "         'lowincom': 733,\n",
       "         'look': 35887,\n",
       "         'alik': 664,\n",
       "         'includ': 48089,\n",
       "         'lack': 5478,\n",
       "         'meaning': 792,\n",
       "         'involv': 12069,\n",
       "         'middl': 7134,\n",
       "         'uppermiddleclass': 54,\n",
       "         'also': 74709,\n",
       "         'extens': 3000,\n",
       "         'whether': 17670,\n",
       "         'noth': 8998,\n",
       "         'surpris': 7299,\n",
       "         'though': 19887,\n",
       "         'expect': 20802,\n",
       "         'confound': 159,\n",
       "         'affluent': 474,\n",
       "         'respond': 6035,\n",
       "         'attempt': 6048,\n",
       "         'interfer': 741,\n",
       "         'curriculum': 577,\n",
       "         'intern': 18337,\n",
       "         'quit': 6095,\n",
       "         'respons': 12423,\n",
       "         'note': 13712,\n",
       "         'anyth': 8360,\n",
       "         'triedandtru': 35,\n",
       "         'approach': 7763,\n",
       "         'inflex': 52,\n",
       "         'regularli': 1750,\n",
       "         'pressur': 6231,\n",
       "         'thing': 28687,\n",
       "         'live': 33023,\n",
       "         'dissent': 796,\n",
       "         'democraci': 2448,\n",
       "         'modal': 59,\n",
       "         'trigger': 997,\n",
       "         'south': 15691,\n",
       "         'carolina': 3990,\n",
       "         'gov': 2688,\n",
       "         'nikki': 192,\n",
       "         'haley': 343,\n",
       "         'ap': 7316,\n",
       "         'presidentelect': 3115,\n",
       "         'donald': 8486,\n",
       "         'trump': 31908,\n",
       "         'tap': 1901,\n",
       "         'smart': 2281,\n",
       "         'tough': 3935,\n",
       "         'women': 19539,\n",
       "         'ambassador': 1935,\n",
       "         'unit': 41155,\n",
       "         'betsi': 281,\n",
       "         'devo': 90,\n",
       "         'secretari': 6829,\n",
       "         'excel': 2501,\n",
       "         'pick': 8243,\n",
       "         'fight': 10699,\n",
       "         'demand': 8246,\n",
       "         'abl': 10040,\n",
       "         'choos': 3809,\n",
       "         'child': 7463,\n",
       "         'potenti': 8155,\n",
       "         'teacher': 6352,\n",
       "         'union': 11632,\n",
       "         'depart': 17831,\n",
       "         'even': 50213,\n",
       "         'republican': 20709,\n",
       "         'alreadi': 14213,\n",
       "         'hate': 2571,\n",
       "         'least': 15628,\n",
       "         'she': 3726,\n",
       "         'effect': 12860,\n",
       "         'rave': 238,\n",
       "         'head': 16193,\n",
       "         'michigan': 3095,\n",
       "         'gop': 1266,\n",
       "         'activist': 2639,\n",
       "         'philanthropist': 297,\n",
       "         'foster': 1586,\n",
       "         'dramat': 2243,\n",
       "         'prokid': 2,\n",
       "         'multipl': 2970,\n",
       "         'guess': 1932,\n",
       "         'citi': 44864,\n",
       "         'charter': 1335,\n",
       "         'come': 38052,\n",
       "         'januari': 5657,\n",
       "         'go': 56561,\n",
       "         'potent': 500,\n",
       "         'friend': 18759,\n",
       "         'meanwhil': 2885,\n",
       "         'prove': 4958,\n",
       "         'yet': 14472,\n",
       "         'he': 12904,\n",
       "         'will': 3639,\n",
       "         'work': 68192,\n",
       "         'critic': 14751,\n",
       "         'within': 9070,\n",
       "         'word': 11450,\n",
       "         'primari': 4155,\n",
       "         'exampl': 9434,\n",
       "         'everyth': 8448,\n",
       "         'governor': 7492,\n",
       "         'doesnt': 10045,\n",
       "         'easili': 2937,\n",
       "         'couldv': 70,\n",
       "         'gotten': 1675,\n",
       "         'blackbal': 9,\n",
       "         'inde': 3365,\n",
       "         'rise': 9034,\n",
       "         'star': 12267,\n",
       "         'let': 12045,\n",
       "         'gain': 7154,\n",
       "         'crucial': 2241,\n",
       "         'experi': 11129,\n",
       "         'en': 1664,\n",
       "         'rout': 3619,\n",
       "         'presum': 1172,\n",
       "         'offic': 33823,\n",
       "         'send': 6086,\n",
       "         'interest': 18587,\n",
       "         'messag': 7868,\n",
       "         'america': 14429,\n",
       "         'repres': 13246,\n",
       "         'daughter': 9811,\n",
       "         'indian': 4666,\n",
       "         'immigr': 7873,\n",
       "         'share': 21480,\n",
       "         'never': 21846,\n",
       "         'follow': 18289,\n",
       "         'basketbal': 3768,\n",
       "         'dont': 29962,\n",
       "         'realli': 18231,\n",
       "         'care': 15989,\n",
       "         'happen': 14375,\n",
       "         'talk': 19578,\n",
       "         'owner': 8913,\n",
       "         'player': 19021,\n",
       "         'tv': 4839,\n",
       "         'watch': 13194,\n",
       "         'game': 40400,\n",
       "         'im': 19999,\n",
       "         'sure': 9550,\n",
       "         'wouldnt': 3474,\n",
       "         'team': 31264,\n",
       "         'playoff': 3196,\n",
       "         'came': 17215,\n",
       "         'nba': 2567,\n",
       "         'audienc': 6204,\n",
       "         'money': 20217,\n",
       "         'made': 38341,\n",
       "         'lie': 3852,\n",
       "         'elsewher': 2390,\n",
       "         'numyearold': 11723,\n",
       "         'son': 12995,\n",
       "         'nowher': 962,\n",
       "         'took': 16850,\n",
       "         'notic': 3685,\n",
       "         'last': 64481,\n",
       "         'spring': 6045,\n",
       "         'start': 31135,\n",
       "         'ask': 25917,\n",
       "         'husband': 8802,\n",
       "         'play': 46764,\n",
       "         'recess': 1980,\n",
       "         'yard': 4889,\n",
       "         'pivot': 621,\n",
       "         'shoot': 6194,\n",
       "         'chase': 2518,\n",
       "         'ball': 6728,\n",
       "         'lebron': 385,\n",
       "         'jame': 8886,\n",
       "         'dwyan': 125,\n",
       "         'joe': 3948,\n",
       "         'johnson': 6804,\n",
       "         'favorit': 4042,\n",
       "         'dominiqu': 141,\n",
       "         'wilkin': 91,\n",
       "         'beat': 6235,\n",
       "         'jordan': 2060,\n",
       "         'dunk': 458,\n",
       "         'contest': 2754,\n",
       "         'mother': 14325,\n",
       "         'couldnt': 3716,\n",
       "         'hoot': 88,\n",
       "         'sport': 10837,\n",
       "         'simpli': 5864,\n",
       "         'happier': 265,\n",
       "         'take': 43126,\n",
       "         'great': 17409,\n",
       "         'wide': 5873,\n",
       "         'complex': 4565,\n",
       "         'real': 13993,\n",
       "         'requir': 14066,\n",
       "         'hard': 11849,\n",
       "         'anim': 6186,\n",
       "         'love': 21868,\n",
       "         'sold': 6597,\n",
       "         'countless': 730,\n",
       "         'ticket': 6101,\n",
       "         'tshirt': 1014,\n",
       "         'breakfast': 1483,\n",
       "         'told': 22447,\n",
       "         'guy': 8872,\n",
       "         'kid': 7024,\n",
       "         'understand': 8339,\n",
       "         'piqu': 98,\n",
       "         'fragil': 710,\n",
       "         'faberg': 32,\n",
       "         'egg': 2023,\n",
       "         'miss': 11500,\n",
       "         'brother': 9072,\n",
       "         'get': 53968,\n",
       "         'score': 12301,\n",
       "         'point': 31956,\n",
       "         'fall': 11590,\n",
       "         'leagu': 11576,\n",
       "         'learn': 11958,\n",
       "         'stick': 2338,\n",
       "         'hope': 16707,\n",
       "         'good': 29641,\n",
       "         'mind': 7277,\n",
       "         'section': 4025,\n",
       "         'bu': 2948,\n",
       "         'appl': 3533,\n",
       "         'ripe': 319,\n",
       "         'correct': 4284,\n",
       "         'append': 443,\n",
       "         'pari': 4546,\n",
       "         'chocolati': 21,\n",
       "         'rais': 13954,\n",
       "         'bar': 6960,\n",
       "         'dec': 5187,\n",
       "         'jonathan': 2066,\n",
       "         'hay': 855,\n",
       "         'write': 11360,\n",
       "         'greatest': 2329,\n",
       "         'chocol': 1301,\n",
       "         'mr': 216235,\n",
       "         'ever': 10773,\n",
       "         'brussel': 818,\n",
       "         'truli': 2002,\n",
       "         'four': 21867,\n",
       "         'return': 17202,\n",
       "         'frequent': 3207,\n",
       "         'sampl': 2296,\n",
       "         'corn': 1149,\n",
       "         'de': 10419,\n",
       "         'la': 7920,\n",
       "         'toison': 1,\n",
       "         'dor': 63,\n",
       "         'neuhau': 13,\n",
       "         'pierr': 552,\n",
       "         'marcolini': 1,\n",
       "         'leonida': 14,\n",
       "         'cdor': 1,\n",
       "         'believ': 16540,\n",
       "         'disservic': 86,\n",
       "         'concentr': 2051,\n",
       "         'reichman': 17,\n",
       "         'md': 1753,\n",
       "         'morristown': 396,\n",
       "         'nj': 3821,\n",
       "         'pastri': 444,\n",
       "         'herm': 149,\n",
       "         'window': 5019,\n",
       "         'ed': 1472,\n",
       "         'alcock': 5,\n",
       "         'bienstockwilliam': 1,\n",
       "         'palm': 1615,\n",
       "         'beach': 6769,\n",
       "         'garden': 6058,\n",
       "         'fl': 852,\n",
       "         'belov': 4492,\n",
       "         'sara': 612,\n",
       "         'errol': 68,\n",
       "         'paula': 411,\n",
       "         'david': 12116,\n",
       "         'sophi': 298,\n",
       "         'ador': 1474,\n",
       "         'grandfath': 2034,\n",
       "         'lori': 266,\n",
       "         'michel': 1851,\n",
       "         'kristen': 215,\n",
       "         'late': 14794,\n",
       "         'bradley': 1102,\n",
       "         'cherish': 1496,\n",
       "         'roz': 31,\n",
       "         'rae': 142,\n",
       "         'gravesid': 216,\n",
       "         'menorah': 87,\n",
       "         'west': 18300,\n",
       "         'wednesday': 16097,\n",
       "         'februari': 4086,\n",
       "         'numnum': 26986,\n",
       "         'pm': 38544,\n",
       "         'europ': 6906,\n",
       "         'presidenti': 7742,\n",
       "         'term': 9847,\n",
       "         'jacqu': 396,\n",
       "         'chirac': 228,\n",
       "         'said': 315604,\n",
       "         'referendum': 1109,\n",
       "         'held': 11334,\n",
       "         'sept': 7202,\n",
       "         'seven': 7937,\n",
       "         'five': 17352,\n",
       "         'poll': 6230,\n",
       "         'threequart': 316,\n",
       "         'french': 7302,\n",
       "         'support': 25316,\n",
       "         'sevenyear': 191,\n",
       "         'written': 5534,\n",
       "         'fifth': 4192,\n",
       "         'republ': 1831,\n",
       "         'gaull': 67,\n",
       "         'agenc': 15067,\n",
       "         'francepress': 350,\n",
       "         'vatican': 843,\n",
       "         'remarriag': 21,\n",
       "         'prohibit': 1690,\n",
       "         'communion': 212,\n",
       "         'cathol': 3425,\n",
       "         'divorc': 1972,\n",
       "         'remarri': 120,\n",
       "         'priest': 1768,\n",
       "         'lenient': 103,\n",
       "         'parishion': 210,\n",
       "         'coupl': 8697,\n",
       "         'howev': 10764,\n",
       "         'abstain': 123,\n",
       "         'sex': 3969,\n",
       "         'alessandra': 81,\n",
       "         'stanley': 2072,\n",
       "         'nyt': 1813,\n",
       "         'switzerland': 819,\n",
       "         'mossad': 46,\n",
       "         'trial': 6075,\n",
       "         'prosecutor': 5329,\n",
       "         'nummonth': 539,\n",
       "         'jail': 2710,\n",
       "         'sentenc': 4270,\n",
       "         'agent': 5900,\n",
       "         'isra': 4875,\n",
       "         'secret': 4696,\n",
       "         'caught': 3116,\n",
       "         'bungl': 87,\n",
       "         'wiretap': 314,\n",
       "         'fals': 1897,\n",
       "         'earlier': 9428,\n",
       "         'man': 20290,\n",
       "         'place': 27200,\n",
       "         'surveil': 1070,\n",
       "         'suspect': 4850,\n",
       "         'link': 4724,\n",
       "         'hezbollah': 717,\n",
       "         'rule': 15616,\n",
       "         'reuter': 7197,\n",
       "         'asia': 2693,\n",
       "         'cambodia': 263,\n",
       "         'khmer': 100,\n",
       "         'roug': 423,\n",
       "         'reach': 11600,\n",
       "         'provision': 227,\n",
       "         'accord': 20942,\n",
       "         'arrang': 3540,\n",
       "         'genocid': 556,\n",
       "         'leader': 17426,\n",
       "         'spokesman': 6714,\n",
       "         'agreement': 6986,\n",
       "         'law': 23572,\n",
       "         'pave': 515,\n",
       "         'parliament': 2696,\n",
       "         'opposit': 6273,\n",
       "         'india': 5390,\n",
       "         'puzzl': 1148,\n",
       "         'tiger': 1686,\n",
       "         'death': 13320,\n",
       "         'rare': 4877,\n",
       "         'zoo': 655,\n",
       "         'eastern': 3809,\n",
       "         'orissa': 6,\n",
       "         'postmortem': 68,\n",
       "         'suggest': 12804,\n",
       "         'die': 14242,\n",
       "         'parasit': 217,\n",
       "         'infect': 1955,\n",
       "         'although': 9758,\n",
       "         'suspicion': 951,\n",
       "         'fallen': 1810,\n",
       "         'medic': 9931,\n",
       "         'use': 51768,\n",
       "         'p': 3417,\n",
       "         'j': 8620,\n",
       "         'anthoni': 2703,\n",
       "         'popup': 332,\n",
       "         'club': 9537,\n",
       "         'temporari': 1543,\n",
       "         'parti': 20393,\n",
       "         'nontradit': 94,\n",
       "         'space': 10100,\n",
       "         'moment': 9042,\n",
       "         'nightclub': 626,\n",
       "         'face': 17901,\n",
       "         'citywid': 268,\n",
       "         'crackdown': 751,\n",
       "         'stem': 1732,\n",
       "         'complaint': 3397,\n",
       "         'nois': 1237,\n",
       "         'promot': 6067,\n",
       "         'creativ': 3556,\n",
       "         'instead': 9552,\n",
       "         'venu': 1057,\n",
       "         'boom': 1762,\n",
       "         'room': 16437,\n",
       "         'week': 39204,\n",
       "         'seem': 23067,\n",
       "         'tire': 2065,\n",
       "         'put': 22572,\n",
       "         'velvet': 325,\n",
       "         'rope': 534,\n",
       "         'plug': 532,\n",
       "         'turntabl': 93,\n",
       "         'recent': 26251,\n",
       "         'month': 30962,\n",
       "         'taken': 9884,\n",
       "         'dim': 333,\n",
       "         'sum': 1195,\n",
       "         'parlor': 292,\n",
       "         'brooklyn': 8858,\n",
       "         'restaur': 8381,\n",
       "         'strip': 2219,\n",
       "         'midtown': 918,\n",
       "         'vacant': 465,\n",
       "         'warehous': 788,\n",
       "         'waterfront': 594,\n",
       "         'park': 17796,\n",
       "         'playground': 436,\n",
       "         'laundromat': 59,\n",
       "         'complet': 11096,\n",
       "         'towelclad': 1,\n",
       "         'bartend': 335,\n",
       "         'detergentthem': 1,\n",
       "         'drink': 3969,\n",
       "         'legal': 8991,\n",
       "         'add': 5881,\n",
       "         'thrill': 1196,\n",
       "         'young': 16478,\n",
       "         'mean': 14595,\n",
       "         'outgo': 262,\n",
       "         'type': 4694,\n",
       "         'fashion': 5002,\n",
       "         'music': 22411,\n",
       "         'imageconsci': 6,\n",
       "         'bit': 6839,\n",
       "         'seva': 6,\n",
       "         'granik': 9,\n",
       "         'ad': 25770,\n",
       "         'outsid': 10926,\n",
       "         'unus': 195,\n",
       "         'havent': 2354,\n",
       "         'entir': 7220,\n",
       "         'popular': 7422,\n",
       "         'spot': 5768,\n",
       "         'palac': 1367,\n",
       "         'chines': 6652,\n",
       "         'banquet': 162,\n",
       "         'hall': 8111,\n",
       "         'manhattan': 11224,\n",
       "         'bridg': 3806,\n",
       "         'pussycat': 41,\n",
       "         'loung': 787,\n",
       "         'seedi': 81,\n",
       "         'financi': 13936,\n",
       "         'district': 9498,\n",
       "         'carlo': 1333,\n",
       "         'quirart': 1,\n",
       "         'smile': 2655,\n",
       "         'jane': 1710,\n",
       "         'ballroom': 526,\n",
       "         'westway': 9,\n",
       "         'got': 17355,\n",
       "         'current': 12013,\n",
       "         'crop': 1264,\n",
       "         'blur': 484,\n",
       "         'line': 18276,\n",
       "         'oneoff': 98,\n",
       "         'regular': 3639,\n",
       "         'rove': 392,\n",
       "         'affair': 3776,\n",
       "         'hop': 504,\n",
       "         'limit': 9626,\n",
       "         'engag': 4637,\n",
       "         'close': 21913,\n",
       "         'whim': 169,\n",
       "         'fickl': 102,\n",
       "         'clientel': 182,\n",
       "         'frankli': 520,\n",
       "         'depress': 2219,\n",
       "         'trend': 3595,\n",
       "         'serg': 92,\n",
       "         'becker': 294,\n",
       "         'nightlif': 80,\n",
       "         'pub': 506,\n",
       "         'esquina': 7,\n",
       "         'lili': 542,\n",
       "         'caribbean': 843,\n",
       "         'houston': 3994,\n",
       "         'street': 38589,\n",
       "         'antinight': 1,\n",
       "         'sens': 9042,\n",
       "         'appropri': 2573,\n",
       "         'exist': 5786,\n",
       "         'unpolish': 23,\n",
       "         'better': 16645,\n",
       "         'think': 34172,\n",
       "         'spend': 11598,\n",
       "         'ton': 1206,\n",
       "         'light': 9908,\n",
       "         'furnitur': 1494,\n",
       "         'honestli': 463,\n",
       "         'none': 3507,\n",
       "         'mia': 278,\n",
       "         'moretti': 33,\n",
       "         'indemand': 20,\n",
       "         'dj': 667,\n",
       "         'who': 1746,\n",
       "         'madam': 272,\n",
       "         'wong': 407,\n",
       "         'dark': 4235,\n",
       "         'obviou': 1948,\n",
       "         'liquor': 483,\n",
       "         'licens': 3019,\n",
       "         'cabaret': 471,\n",
       "         'kitschier': 1,\n",
       "         'farflung': 140,\n",
       "         'cheeki': 95,\n",
       "         'appeal': 6557,\n",
       "         'china': 12406,\n",
       "         'chalet': 44,\n",
       "         'dragonandneon': 1,\n",
       "         'lower': 8339,\n",
       "         'broadway': 5351,\n",
       "         'hideaway': 50,\n",
       "         'art': 25399,\n",
       "         'crowd': 5765,\n",
       "         'balmi': 53,\n",
       "         'thursday': 16651,\n",
       "         'releas': 13069,\n",
       "         ...})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([word for list in list(itertools.chain(X_train.loc[X_train['type'] == 'reliable'].content)) for word in list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d82b2e002de3f5f2748faab7eed39a54b7eae736eec0eed65c518ce11052f6ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
